This page is about reimplemented Typed Template Haskell to fix unsoundness issues
such as #15863.

The primary reference for implementation issues is

   	[Understanding the interaction between elaboration and quotation](https://research-information.bris.ac.uk/ws/portalfiles/portal/298086479/Final_Copy_2021_03_23_Pickering_M_PhD.pdf) Matthew Pickering PhD Thesis


# Step 1: Typed Internal Representation

The key to soundness is using an internal representation which preserves type
information from the host to the target. Therefore when the host decides that an
expression has a certain type, this information is stored in the representation and
communicated to the host when spliced into the program.

The proposed representation is a triple containing

  * An opaque serialised `ByteString` which represents a core expression.
  * A splice environment for expressions
  * A splice environment for types
  * A renaming environment to support dynamic variable renaming (S4.1.1)

Splices are run in the desugarer. Evaluating a splice produces a core expression of
the correct type which can be directly inserted into the start of the optimisation pipeline.

By using a typed representation we have to care about the binding sites of implicit
evidence introduced by the compiler. The most problematic cases are to do with
constraints and type variables.

# Step 2: CodeC constraints

CodeC constraints allow us to be precise about which stage constraints are available to
be used. For a constraint `c`, `CodeC c` indicates that C will be available in the
next stage.

Type class methods used inside quotations can only be satisfied by `CodeC` constraints.

`CodeC` is formalised and described in [Staging With Class: A Specification for Typed Template Haskell](https://xnning.github.io/papers/staging-with-class.pdf)

## Implementation

When constraints are generated they are given a level. The level of a constraint
is the level that the evidence for a constraint needs to be bound at.

Implication constraints need to be introduced at the boundaries of quotes and splices
so that there is an appropiate places to bind evidence.

The constraint solver is augmented to solve CodeC constraint form by using the
rules of the formalism.

### Solving CodeC constraints

For a wanted constraint CodeC c at level k
then the constraint is solved by a given constraint c at level k + 1. The evidence for
a wanted CodeC constraint is a quoted variable which represents the evidence for c. As
the constraint c is from level k + 1 then the evidence variable is guaranteed to be bound
at level k + 1.

For a CodeC c given at level k, the constraint solver will use this
information to also solve a c wanted at level k + 1 and this is implemented by rewriting
the CodeC c given into a c given. This transformation is performed by using a splice, as
guided by the elaboration rules in the formalism

Therefore both wanted and given constraints will be simplified in order to remove the
CodeC constraint form so that eventually the constraint solver is left with a set of levelled
constraints without any mention of CodeC. The rewriting is confluent as each rewriting
step acts to remove a CodeC layer.

### Generating Residual Constraints

At the end of the constraint solving process
there may be unsolved constraints. Usually during generalisation the type inference
engine will infer a type with a context containing these constraints. Now all the
constraints are also level aware, the generalisation process needs to account for levels.
The top-level of a program is at level 0, therefore any constraints which are at level 0
can be generalised as normal. A constraint at level k where k > 0 can be generalised to
k applications of CodeC. A constraint at level k where k < 0 is unsolvable by any rules
and should be reported as unsolvable to the user.

### Location of Evidence

Engineering where the typchecker places it's evidence when solving CodeC (ie
making sure the level invariant holds) is quite tricky. See "Location of Evidence"
in the thesis for some examples and a discussion about "Expression holes".


# Step 3: Type Variables

As the internal representation is typed,
For example, the quoted identity function can be written as follows.

```
qid :: forall a . Code m (a -> a)
qid = [|| id ||]
```

But if applied to a specific type, potential far away from where it is defined.

```
qidInt :: Code m (Int -> Int)
qidInt = qid @Int
```

Then we need to create a representation which looks like:

```
qidInt = (< id @Int, [], [] >)
```

In order to do this, when `qid` is evaluated it must be passed the type `a` it
is applied to. In other words, when doing code generation with typed template haskell
we need an evaluator where type variables are relevant.

The principle idea is

* All packages generate a fat interface file, containing the whole core for the module.
* On demand, when needed for a TH splice, load the necessary modules and translate the
  core into bytecode instructions where the type arguments are relevant.

In order to implement this upstream coordination with cabal will be necessary to
make sure the necessary artifacts for dependent packages are created.

By default cabal is already compiling both static and dynamic object files, and
the dynamic object files are provided just because they are needed to executate
Template Haskell splices (with a dynamically linked compiler executable). The compile
time overhead of -dynamic-too is significantly higher than writing a fat interface file.

The advantages to fat interface files are growing in number:
  * Overcomes issues with slow linking when using object files (#21700)
  * Faster load times when loading projects into GHC (no typechecking required)
  * Convenient to rebuild for different targets on the fly (see above)


## Implementation

A few things are currently underspecified:

* How to implicitly work out the stage translations of types.
* What form the evidence takes.



# Issue List

https://gitlab.haskell.org/ghc/ghc/-/issues/?label_name%5B%5D=typed%20TemplateHaskell



